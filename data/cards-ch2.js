window.CARDS_CH2 = [
    { id: "ch2-0001", chapter: 2, term: "半加算器", definition: "1ビットの2入力を加算し，和(S)と桁上がり(C)を出力する回路。一般に Sは排他的論理和(XOR)，Cは論理積(AND)で実現する。",
        extraExplain: "ポイント: 半加算器は「1・ビット・2」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「半加算器・1・ビット・2・加算」を口に出して言えるように。"
    },
    { id: "ch2-0002", chapter: 2, term: "全加算器", definition: "1ビットの2入力に加えて，下位桁からの桁上がり(Cin)も加算し，和(S)と桁上がり(Cout)を出力する回路。",
        extraExplain: "ポイント: 全加算器は「1・ビット・2」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「全加算器・1・ビット・2・えて」を口に出して言えるように。"
    },
    { id: "ch2-0003", chapter: 2, term: "後置記法（逆ポーランド記法）", definition: "演算子を被演算子の後ろに置く記法。スタックで機械的に評価できるため，式の処理に向く。",
        extraExplain: "ポイント: 後置記法（逆ポーランド記法）は「演算子・被演算子・ろに」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「後置記法・ポーランド・記法・演算子・被演算子」を口に出して言えるように。"
    },
    { id: "ch2-0004", chapter: 2, term: "前置記法（ポーランド記法）", definition: "演算子を被演算子の前に置く記法。例：+AB のように書く。",
        extraExplain: "ポイント: 前置記法（ポーランド記法）は「演算子・被演算子・記法」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「前置記法・ポーランド・記法・演算子・被演算子」を口に出して言えるように。"
    },
    { id: "ch2-0005", chapter: 2, term: "中置記法", definition: "演算子を被演算子の間に置く一般的な記法。例：A+B のように書く。",
        extraExplain: "ポイント: 中置記法は「演算子・被演算子・一般的」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「中置記法・演算子・被演算子・一般的・記法」を口に出して言えるように。"
    },
    { id: "ch2-0006", chapter: 2, term: "機械学習", definition: "データから規則性やモデルを学習し，予測・分類などに利用する技術（人間の学習能力をコンピュータで再現する考え方）。",
        extraExplain: "ポイント: 機械学習は「から・規則性・モデル」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「機械学習・から・規則性・モデル・学習」を口に出して言えるように。"
    },
    { id: "ch2-0007", chapter: 2, term: "教師あり学習", definition: "入力データと正解データ（ラベル）を与えて学習させる機械学習の方式。",
        extraExplain: "ポイント: 教師あり学習は「正解・ラベル・えて」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「教師・あり・学習・正解・ラベル」を口に出して言えるように。"
    },
    { id: "ch2-0008", chapter: 2, term: "教師なし学習", definition: "入力データのみを与え，データの構造（クラスタなど）を見いだす機械学習の方式。",
        extraExplain: "ポイント: 教師なし学習は「のみを・構造・クラスタ」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「教師・なし・学習・のみを・構造」を口に出して言えるように。"
    },
    { id: "ch2-0009", chapter: 2, term: "ニューラルネットワーク", definition: "人間の神経細胞（ニューロン）の結合を模したモデル。重み付き和を計算し，活性化関数で出力を決める。",
        extraExplain: "ポイント: ニューラルネットワークは「人間・神経細胞・ニューロン」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「ニューラルネットワーク・人間・神経細胞・ニューロン・結合」を口に出して言えるように。"
    },
    { id: "ch2-0010", chapter: 2, term: "活性化関数", definition: "ニューロンの計算結果を次の層へ渡す出力に変換する関数（例：ReLU，シグモイドなど）。",
        extraExplain: "ポイント: 活性化関数は「ニューロン・計算結果・変換」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「活性化関数・ニューロン・計算結果・変換・する」を口に出して言えるように。"
    },
    { id: "ch2-0011", chapter: 2, term: "ディープラーニング", definition: "多層（深い）ニューラルネットワークを用いた機械学習。特徴量を自動で学習しやすい。",
        extraExplain: "ポイント: ディープラーニングは「多層・ニューラルネットワーク・いた」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「ディープラーニング・多層・ニューラルネットワーク・いた・機械学習」を口に出して言えるように。"
    },
    { id: "ch2-0012", chapter: 2, term: "生成AI", definition: "学習したデータの傾向に基づき，テキスト・音声・画像・動画などの新しいコンテンツを生成するAI。",
        extraExplain: "ポイント: 生成AIは「学習・した・傾向」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「生成・AI・学習・した・傾向」を口に出して言えるように。"
    },
    { id: "ch2-0013", chapter: 2, term: "プロンプトエンジニアリング", definition: "生成AIに与える指示（プロンプト）を工夫して，望む出力に近づけるための調整・最適化。",
        extraExplain: "ポイント: プロンプトエンジニアリングは「生成・AI・える」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「プロンプトエンジニアリング・生成・AI・える・指示」を口に出して言えるように。"
    },
    { id: "ch2-0014", chapter: 2, term: "ディープフェイク", definition: "本物と見分けがつきにくい偽の音声・画像・動画などを作る手法。",
        extraExplain: "ポイント: ディープフェイクは「本物・見分・けがつきにくい」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「ディープフェイク・本物・見分・けがつきにくい・音声」を口に出して言えるように。"
    },
    { id: "ch2-0015", chapter: 2, term: "ハルシネーション", definition: "生成AIが誤った内容を，もっともらしく作り出してしまう現象。",
        extraExplain: "ポイント: ハルシネーションは「生成・AI・った」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「ハルシネーション・生成・AI・った・内容」を口に出して言えるように。"
    },
    { id: "ch2-0016", chapter: 2, term: "基盤モデル（Foundation Model）", definition: "大量データで事前学習した汎用的なモデル。用途に応じて追加学習や調整を行って使う。",
        extraExplain: "ポイント: 基盤モデル（Foundation Model）は「大量・事前学習・した」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「基盤・モデル・Foundation・Model・大量」を口に出して言えるように。"
    },
    { id: "ch2-0017", chapter: 2, term: "ファインチューニング", definition: "基盤モデルに追加学習を行い，特定用途に適応させること。",
        extraExplain: "ポイント: ファインチューニングは「基盤・モデル・追加学習」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「ファインチューニング・基盤・モデル・追加学習・特定用途」を口に出して言えるように。"
    },
    { id: "ch2-0018", chapter: 2, term: "ハッシュ法", definition: "キーからハッシュ値を計算し，格納場所（番地）を決めて高速に検索する方式。",
        extraExplain: "ポイント: ハッシュ法は「キー・から・ハッシュ」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「ハッシュ・キー・から・格納場所・番地」を口に出して言えるように。"
    },
    { id: "ch2-0019", chapter: 2, term: "衝突（コリジョン）", definition: "異なるキーが同じハッシュ値になること。ハッシュ法の欠点の一つで，対策（チェイン法など）が必要。",
        extraExplain: "ポイント: 衝突（コリジョン）は「なる・キー・ハッシュ」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「衝突・コリジョン・なる・キー・ハッシュ」を口に出して言えるように。"
    },
    { id: "ch2-0020", chapter: 2, term: "二分探索法", definition: "整列済みデータに対し，中央要素と比較しながら探索範囲を半分に絞っていく探索法。",
        extraExplain: "ポイント: 二分探索法は「整列済・中央要素・比較」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「二分探索法・整列済・中央要素・比較・しながら」を口に出して言えるように。"
    },
    { id: "ch2-0021", chapter: 2, term: "二分探索の前提", definition: "探索対象のデータがあらかじめ整列（ソート）されていること。",
        extraExplain: "ポイント: 二分探索の前提は「探索対象・があらかじめ・整列」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「二分探索・前提・探索対象・があらかじめ・整列」を口に出して言えるように。"
    },
    { id: "ch2-0022", chapter: 2, term: "線形探索法", definition: "先頭から順に比較していく探索法。整列されていなくても使えるが，時間がかかりやすい。",
        extraExplain: "ポイント: 線形探索法は「先頭・から・比較」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「線形探索法・先頭・から・比較・していく」を口に出して言えるように。"
    },
    { id: "ch2-0023", chapter: 2, term: "再帰呼出し", definition: "関数（手続）が処理の途中で自分自身を呼び出すこと。",
        extraExplain: "ポイント: 再帰呼出しは「関数・手続・途中」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「再帰呼出・関数・手続・途中・自分自身」を口に出して言えるように。"
    },
    { id: "ch2-0024", chapter: 2, term: "再帰的アルゴリズムの典型", definition: "総和・積・階乗などを再帰で求める問題が典型として出題されやすい。",
        extraExplain: "ポイント: 再帰的アルゴリズムの典型は「総和・階乗・などを」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「再帰的・アルゴリズム・典型・総和・階乗」を口に出して言えるように。"
    },
    { id: "ch2-0025", chapter: 2, term: "計算量（オーダー）", definition: "入力サイズnに対する処理時間や手数の増え方を表す。O( )で表記する。",
        extraExplain: "ポイント: 計算量（オーダー）は「サイズ・n・する」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「計算量・オーダー・サイズ・n・する」を口に出して言えるように。"
    },
    { id: "ch2-0026", chapter: 2, term: "ハッシュ法の計算量", definition: "平均的には O(1) で検索できる（衝突が多いと性能が低下する）。",
        extraExplain: "ポイント: ハッシュ法の計算量は「平均的・には・O」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「ハッシュ・計算量・平均的・には・O」を口に出して言えるように。"
    },
    { id: "ch2-0027", chapter: 2, term: "二分探索法の計算量", definition: "探索範囲を半分にしていくため O(log n)。",
        extraExplain: "ポイント: 二分探索法の計算量は「探索範囲・半分・にしていくため」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「二分探索法・計算量・探索範囲・半分・にしていくため」を口に出して言えるように。"
    },
    { id: "ch2-0028", chapter: 2, term: "線形探索法の計算量", definition: "最悪で全要素を見るため O(n)。",
        extraExplain: "ポイント: 線形探索法の計算量は「最悪・全要素・るため」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「線形探索法・計算量・最悪・全要素・るため」を口に出して言えるように。"
    },
    { id: "ch2-0029", chapter: 2, term: "クイックソートの計算量", definition: "平均 O(n log n)。基準値（ピボット）で分割して再帰的に整列する。最悪は O(n^2) になる場合がある。",
        extraExplain: "ポイント: クイックソートの計算量は「O・n・log」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：ピボット=5なら、[3,8,1,7] → [3,1] と [8,7] に分けて再帰。\\n暗記：キーワード「クイックソート・計算量・O・n・log」を口に出して言えるように。"
    },
    { id: "ch2-0030", chapter: 2, term: "再入可能（リエントラント）", definition: "複数の処理から同時に呼び出されても正しく動作できる性質（共有資源の扱いに注意が必要）。",
        extraExplain: "ポイント: 再入可能（リエントラント）は「複数・から・同時」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「再入可能・リエントラント・複数・から・同時」を口に出して言えるように。"
    },
    { id: "ch2-0031", chapter: 2, term: "Javaアプレット", definition: "サーバからダウンロードし，Webブラウザ上で実行されるJavaプログラム（現在はほぼ使われない）。",
        extraExplain: "ポイント: Javaアプレットは「サーバ・から・ダウンロード」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「Java・アプレット・サーバ・から・ダウンロード」を口に出して言えるように。"
    },
    { id: "ch2-0032", chapter: 2, term: "Javaサーブレット", definition: "サーバ側で実行され，動的なWebページ生成などに利用されるJavaプログラム。",
        extraExplain: "ポイント: Javaサーブレットは「サーバ・され・動的」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「Java・サーブレット・サーバ・され・動的」を口に出して言えるように。"
    },
    { id: "ch2-0033", chapter: 2, term: "HTML", definition: "Webページの論理構造（見出し・段落・リンク等）や要素をタグで記述するマークアップ言語。",
        extraExplain: "ポイント: HTMLは「Web・ページ・論理構造」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「HTML・Web・ページ・論理構造・見出」を口に出して言えるように。"
    },
    { id: "ch2-0034", chapter: 2, term: "HTMLのタグ", definition: "HTMLでは要素（タグ）の種類と使い方が規定されている（勝手なタグは基本的に定義しない）。",
        extraExplain: "ポイント: HTMLのタグは「HTML・では・要素」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「HTML・タグ・では・要素・種類」を口に出して言えるように。"
    },
    { id: "ch2-0035", chapter: 2, term: "XML", definition: "利用者が目的に応じて任意のタグを定義できるマークアップ言語。",
        extraExplain: "ポイント: XMLは「利用者・目的・じて」に注目して意味を押さえる。\\nひっかけ: 定義のキーワード（主語・目的・効果）を1つずつ確認。\\n例: 例：試験では“目的→効果”の流れで選択肢を消す。\\n暗記：キーワード「XML・利用者・目的・じて・任意」を口に出して言えるように。"
    },
    { id: "ch2-0036", chapter: 2, term: "過学習", definition: "学習データに過度に適合してしまい、未知データで性能が落ちる（汎化性能が低い）状態。",
        extraExplain: "ポイント: 過学習の要点を一言で言えるように。\nひっかけ: 用語の似た言い回し（近い概念）と混同しない。\n例: 実務/試験でどう出るかを1つ想像する。\n暗記: キーワードを3つに分解して口に出す。"
    },
    { id: "ch2-0037", chapter: 2, term: "エッジAI", definition: "クラウドではなく端末側（エッジ：スマホ、IoT機器など）でAI推論を実行する方式。低遅延・通信削減・プライバシー面で有利。",
        extraExplain: "ポイント: エッジAIの要点を一言で言えるように。\nひっかけ: 用語の似た言い回し（近い概念）と混同しない。\n例: 実務/試験でどう出るかを1つ想像する。\n暗記: キーワードを3つに分解して口に出す。"
    },
    { id: "ch2-0038", chapter: 2, term: "R", definition: "統計解析とグラフ作成に強いオープンソースのプログラミング言語／実行環境。",
        extraExplain: "ポイント: Rの要点を一言で言えるように。\nひっかけ: 用語の似た言い回し（近い概念）と混同しない。\n例: 実務/試験でどう出るかを1つ想像する。\n暗記: キーワードを3つに分解して口に出す。"
    },
    { id: "ch2-0039", chapter: 2, term: "ベイジアンフィルタリング", definition: "ベイズ推定に基づき、観測値から確率分布（状態）を逐次更新してノイズを抑え推定する手法（例：カルマン/パーティクルフィルタ）。",
        extraExplain: "ポイント: ベイジアンフィルタリングの要点を一言で言えるように。\nひっかけ: 用語の似た言い回し（近い概念）と混同しない。\n例: 実務/試験でどう出るかを1つ想像する。\n暗記: キーワードを3つに分解して口に出す。"
    }
];
